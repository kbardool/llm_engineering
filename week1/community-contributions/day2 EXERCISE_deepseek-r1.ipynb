{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdcd35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull deepseek-r1:8b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c106420",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T01:24:36.330386Z",
     "iopub.status.busy": "2025-04-26T01:24:36.329893Z",
     "iopub.status.idle": "2025-04-26T01:24:36.727051Z",
     "shell.execute_reply": "2025-04-26T01:24:36.726385Z",
     "shell.execute_reply.started": "2025-04-26T01:24:36.330366Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "import ollama\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22d62f00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T01:25:22.008418Z",
     "iopub.status.busy": "2025-04-26T01:25:22.007887Z",
     "iopub.status.idle": "2025-04-26T01:25:22.011600Z",
     "shell.execute_reply": "2025-04-26T01:25:22.010939Z",
     "shell.execute_reply.started": "2025-04-26T01:25:22.008397Z"
    }
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"deepseek-r1:8b\"\n",
    "MODEL = \"deepseek-r1:1.5b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T01:24:38.718910Z",
     "iopub.status.busy": "2025-04-26T01:24:38.718453Z",
     "iopub.status.idle": "2025-04-26T01:24:38.723749Z",
     "shell.execute_reply": "2025-04-26T01:24:38.723026Z",
     "shell.execute_reply.started": "2025-04-26T01:24:38.718888Z"
    }
   },
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "# If you're not familiar with Classes, check out the \"Intermediate Python\" notebook\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4449b7dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T01:24:39.649457Z",
     "iopub.status.busy": "2025-04-26T01:24:39.648989Z",
     "iopub.status.idle": "2025-04-26T01:24:39.652675Z",
     "shell.execute_reply": "2025-04-26T01:24:39.652037Z",
     "shell.execute_reply.started": "2025-04-26T01:24:39.649430Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daca9448",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T01:24:40.098046Z",
     "iopub.status.busy": "2025-04-26T01:24:40.097775Z",
     "iopub.status.idle": "2025-04-26T01:24:40.101723Z",
     "shell.execute_reply": "2025-04-26T01:24:40.101079Z",
     "shell.execute_reply.started": "2025-04-26T01:24:40.098030Z"
    }
   },
   "outputs": [],
   "source": [
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ec9d5d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T01:24:41.179515Z",
     "iopub.status.busy": "2025-04-26T01:24:41.178899Z",
     "iopub.status.idle": "2025-04-26T01:24:41.182942Z",
     "shell.execute_reply": "2025-04-26T01:24:41.182322Z",
     "shell.execute_reply.started": "2025-04-26T01:24:41.179490Z"
    }
   },
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e1ab04a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T01:24:42.148685Z",
     "iopub.status.busy": "2025-04-26T01:24:42.148414Z",
     "iopub.status.idle": "2025-04-26T01:24:42.152617Z",
     "shell.execute_reply": "2025-04-26T01:24:42.151812Z",
     "shell.execute_reply.started": "2025-04-26T01:24:42.148669Z"
    }
   },
   "outputs": [],
   "source": [
    "# And now: call the OpenAI API. You will get very familiar with this!\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = ollama.chat(\n",
    "        model = MODEL,\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d3b5628",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T01:24:43.118885Z",
     "iopub.status.busy": "2025-04-26T01:24:43.118412Z",
     "iopub.status.idle": "2025-04-26T01:24:43.122465Z",
     "shell.execute_reply": "2025-04-26T01:24:43.121660Z",
     "shell.execute_reply.started": "2025-04-26T01:24:43.118864Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "938e5633",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T01:28:55.833561Z",
     "iopub.status.busy": "2025-04-26T01:28:55.832837Z",
     "iopub.status.idle": "2025-04-26T01:28:59.122879Z",
     "shell.execute_reply": "2025-04-26T01:28:59.122041Z",
     "shell.execute_reply.started": "2025-04-26T01:28:55.833538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Alright, I need to create a summary of the website titled \"Home - Edward Donner.\" Let's see what information is there.\n",
       "\n",
       "First, it seems to be a platform related to LLMs, which stands for Large Language Models. There are mentions like \"Connect Four,\" \"Outsmart,\" and an arena for talent. The site also talks about Ed being the co-founder of Nebula.io, applying AI in discovering potential.\n",
       "\n",
       "There are posts mentioning events like the Agentic AI Engineering Course on April 21, 2025, and a Welcome post on November 13, 2024. It's got some links to resources for mastering LLM engineering and an newsletter subscription.\n",
       "\n",
       "The site has a navigation menu with options Connect Four, Outsmart, and Explore, all linked to LLMs. The About section is quite brief but mentions Ed as the co-founder of Nebula.io experimenting with LLMs.\n",
       "\n",
       "There are several social media handles: LinkedIn, Twitter, Facebook, and a newsletter subscription link.\n",
       "\n",
       "In summary, Edward Donner hosts a platform focused on AI and LLMs, promoting events and resources for discovering potential and managing talent. The site is navigated through Connect Four, Outsmart, or Explore sections.\n",
       "</think>\n",
       "\n",
       "Edward Donner operates a platform centered around Artificial Intelligence (AI) and Large Language Models (LLMs). It features events such as the Agentic AI Engineering Course on April 21, 2025, and an introductory Welcome post. The site highlights Ed's role as co-founder of Nebula.io, applying AI to discover talent. Social media handles include LinkedIn, Twitter, Facebook, and newsletter subscriptions.\n",
       "\n",
       "Navigation:\n",
       "- **Connect Four**: A game where players compete for a spot.\n",
       "- **Outsmart**: An arena where LLMs face off in strategic challenges.\n",
       "- **Explore**: The main page offering resources and events.\n",
       "\n",
       "The platform promotes discovery of potential and talent management through various sections."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7063335d-d260-427e-bd63-79640fb1626b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llms]",
   "language": "python",
   "name": "conda-env-llms-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
